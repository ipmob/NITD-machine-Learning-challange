{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of v01 LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipmob/NITD-machine-Learning-challange/blob/master/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7Pwq9fDJu2sG",
        "colab_type": "code",
        "outputId": "8cf870e0-468d-49fd-f3c3-26982256c66b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -i https://test.pypi.org/simple/ supportlib\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Collecting supportlib\n",
            "  Downloading https://test-files.pythonhosted.org/packages/c7/e8/a44bb606fca2603f0c79e8593fe0f6f1626dee5bad5177afb9ee260fd223/supportlib-0.1.0-py3-none-any.whl\n",
            "Installing collected packages: supportlib\n",
            "Successfully installed supportlib-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BaFhanfbjPs3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_xd0oztjDzh",
        "colab_type": "code",
        "outputId": "9be2dd89-b488-4d53-d244-42b4b879ed61",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "import supportlib.gettingdata as getdata\n",
        "getdata.kaggle()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8a0ae148-7218-470e-af44-99a308b31562\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8a0ae148-7218-470e-af44-99a308b31562\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CmLSEOyhu7oS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tTl_vxGPvplJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "goHS1Q1gbtbu",
        "colab_type": "code",
        "outputId": "5d113b34-f90b-45fc-ce10-def60f81860f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d thanakomsn/glove6b300dtxt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading glove6b300dtxt.zip to /content\n",
            " 98% 377M/386M [00:09<00:00, 34.0MB/s]\n",
            "100% 386M/386M [00:09<00:00, 41.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qq9k3g0Alk4k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "getdata.zipextract('/content/glove6b300dtxt.zip')\n",
        "#!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bGotXR6-b2tH",
        "colab_type": "code",
        "outputId": "97f4d47a-6143-44b3-80d0-2ec5957c9554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ipmob/NITD-machine-Learning-challange"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NITD-machine-Learning-challange'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)   \u001b[K\rremote: Counting objects:  16% (2/12)   \u001b[K\rremote: Counting objects:  25% (3/12)   \u001b[K\rremote: Counting objects:  33% (4/12)   \u001b[K\rremote: Counting objects:  41% (5/12)   \u001b[K\rremote: Counting objects:  50% (6/12)   \u001b[K\rremote: Counting objects:  58% (7/12)   \u001b[K\rremote: Counting objects:  66% (8/12)   \u001b[K\rremote: Counting objects:  75% (9/12)   \u001b[K\rremote: Counting objects:  83% (10/12)   \u001b[K\rremote: Counting objects:  91% (11/12)   \u001b[K\rremote: Counting objects: 100% (12/12)   \u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects:   9% (1/11)   \u001b[K\rremote: Compressing objects:  18% (2/11)   \u001b[K\rremote: Compressing objects:  27% (3/11)   \u001b[K\rremote: Compressing objects:  36% (4/11)   \u001b[K\rremote: Compressing objects:  45% (5/11)   \u001b[K\rremote: Compressing objects:  54% (6/11)   \u001b[K\rremote: Compressing objects:  63% (7/11)   \u001b[K\rremote: Compressing objects:  72% (8/11)   \u001b[K\rremote: Compressing objects:  81% (9/11)   \u001b[K\rremote: Compressing objects:  90% (10/11)   \u001b[K\rremote: Compressing objects: 100% (11/11)   \u001b[K\rremote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "Unpacking objects:   8% (1/12)   \rUnpacking objects:  16% (2/12)   \rUnpacking objects:  25% (3/12)   \rUnpacking objects:  33% (4/12)   \rUnpacking objects:  41% (5/12)   \rUnpacking objects:  50% (6/12)   \rUnpacking objects:  58% (7/12)   \rUnpacking objects:  66% (8/12)   \rremote: Total 12 (delta 1), reused 8 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  75% (9/12)   \rUnpacking objects:  83% (10/12)   \rUnpacking objects:  91% (11/12)   \rUnpacking objects: 100% (12/12)   \rUnpacking objects: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sVa2BcBlvqCU",
        "colab_type": "code",
        "outputId": "381cdba7-c1c2-4b88-affc-91d6697c2ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import keras\n",
        "\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cvx0EdUFvsqf",
        "colab_type": "code",
        "outputId": "a2db2fd9-8da3-4868-f681-0e31765641db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import keras\n",
        "\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eoq0CcnvMV_G",
        "colab_type": "code",
        "outputId": "aee0840a-9f94-49fb-a8f8-33cc433a9954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/NITD-machine-Learning-challange/data/train_file.csv')\n",
        "test = pd.read_csv('/content/NITD-machine-Learning-challange/data/test_file.csv')\n",
        "sample = pd.read_csv('/content/NITD-machine-Learning-challange/data/results_file.csv')\n",
        "\n",
        "data.loc[data.Subjects.isnull(), 'Subjects'] = ''\n",
        "test.loc[test.Subjects.isnull(), 'Subjects'] = ''\n",
        "\n",
        "data['PublicationYear'] = data['PublicationYear'].astype('str').map(lambda x: \" \".join(re.findall('\\d{4}', x)))\n",
        "test['PublicationYear'] = test['PublicationYear'].astype('str').map(lambda x: \" \".join(re.findall('\\d{4}', x)))\n",
        "test = test.fillna({'Subjects': \"\", \"Title\": \"\", \"Publisher\": \"\"})\n",
        "data = data.fillna({\"PublicationYear\":\"\",\"Publisher\":\"\"})\n",
        "\n",
        "data['combined'] = data['Subjects'] + \" \" + data['Title'] + \" \" + data['PublicationYear'].astype('str') + \" \" + data['Publisher'] + \" \" + data['Checkouts'].astype('str')\n",
        "test['combined'] = test['Subjects'] + \" \" + test['Title'] + \" \" + test['PublicationYear'].astype('str') + \" \" + test['Publisher'] + \" \" + data['Checkouts'].astype('str')\n",
        "\n",
        "# data['combined'] = data.Subjects.str.cat(' ' + data.Title)\n",
        "# test['combined'] = test_data['Subjects']\n",
        "\n",
        "# data['combined'] = td2['sub']\n",
        "\n",
        "dataMatType = data.MaterialType\n",
        "data.drop(labels = ['MaterialType'], axis = 1, inplace = True)\n",
        "\n",
        "data.combined = data.combined.apply(preprocess_text)\n",
        "test.combined = test.combined.apply(preprocess_text)\n",
        "'''\n",
        "data.Subjects = data.Subjects.apply(preprocess_text)\n",
        "data.Title = data.Title.apply(preprocess_text)\n",
        "test.Subjects = test.Subjects.apply(preprocess_text)\n",
        "test.Title = test.Title.apply(preprocess_text)\n",
        "'''\n",
        "flag = -1\n",
        "labelDict = {}\n",
        "\n",
        "for key in dataMatType.value_counts().keys():\n",
        "  flag += 1\n",
        "  labelDict[key] = flag\n",
        "  \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "maxlen = 25                            \n",
        "\n",
        "max_words = 1000                                    \n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data.combined)\n",
        "\n",
        "dataSequences = tokenizer.texts_to_sequences(data.combined)\n",
        "testSequences = tokenizer.texts_to_sequences(test.combined)\n",
        "\n",
        "data_word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(data_word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 37290 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AmgGkE7lvwc0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import preprocessing\n",
        "x_train = preprocessing.sequence.pad_sequences(dataSequences, maxlen = 25)\n",
        "x_test = preprocessing.sequence.pad_sequences(testSequences, maxlen = 25)\n",
        "\n",
        "train_label = dataMatType.map(labelDict)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "labelDataBinary = to_categorical(train_label)\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(dataMatType), dataMatType)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PFlbzeBoGMX9",
        "colab_type": "code",
        "outputId": "fd0ce82f-c3fb-44e0-a2f4-a15f9069ad57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "glove_dir = '/content'\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.300d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in data_word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_N2BPfk4Ydup",
        "colab_type": "code",
        "outputId": "ed2fff5b-136b-4ab9-9a16-14a645ac0872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "cell_type": "code",
      "source": [
        "reverseLabelDict = {}\n",
        "\n",
        "for key, value in labelDict.items():\n",
        "  reverseLabelDict[value] = key\n",
        "def predict(model, x_test):\n",
        "  predictions = model.predict(x_test)\n",
        "  predictions = pd.Series([np.argmax(i) for i in predictions], index = test.index)\n",
        "  predictions = predictions.map(reverseLabelDict)\n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8e8734745e1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreverseLabelDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabelDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mreverseLabelDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labelDict' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d0f2c9ff-fd65-47ea-f46f-31c4b67ab2cc",
        "id": "p8lV4j7qvUNd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(1200, 1200, input_length=25))\n",
        "\n",
        "'''model.add(Conv1D(256, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "'''\n",
        "\n",
        "\n",
        "model1.add(Conv1D(128, 3,  activation='elu'))\n",
        "model1.add(Dropout(0.6))\n",
        "\n",
        "model1.add(LSTM(400, recurrent_dropout = 0.6, return_sequences = True))\n",
        "model1.add(Dropout(0.4))\n",
        "\n",
        "model1.add(LSTM(400, recurrent_dropout = 0.5))\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "model1.add(Dense(8, activation='softmax'))\n",
        "\n",
        "model1.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model1.fit(x_train, labelDataBinary,\n",
        "                    epochs=16,\n",
        "                    validation_split=0,\n",
        "                    class_weight = class_weights)\n",
        "\n",
        "model1.save('/content/m1.h5')\n",
        "#0.86623 \n",
        "#0.87633\n",
        "\n",
        "predic1 = pd.Series(predict(model1, x_test))\n",
        "submission = pd.concat([test.ID.astype(np.int), predic1], axis = 1)\n",
        "submission.columns = ['ID' , 'MaterialType']\n",
        "submission.to_csv('/content/submition_model1.1_add.csv', index = False, header = True)  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/16\n",
            "31653/31653 [==============================] - 124s 4ms/step - loss: 0.4978 - acc: 0.8612\n",
            "Epoch 2/16\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.4156 - acc: 0.8789\n",
            "Epoch 3/16\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.4048 - acc: 0.8834\n",
            "Epoch 4/16\n",
            "31653/31653 [==============================] - 120s 4ms/step - loss: 0.4032 - acc: 0.8848\n",
            "Epoch 5/16\n",
            "31653/31653 [==============================] - 120s 4ms/step - loss: 0.4009 - acc: 0.8853\n",
            "Epoch 6/16\n",
            "31653/31653 [==============================] - 124s 4ms/step - loss: 0.4006 - acc: 0.8865\n",
            "Epoch 7/16\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.3965 - acc: 0.8874\n",
            "Epoch 8/16\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.3972 - acc: 0.8879\n",
            "Epoch 9/16\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.3981 - acc: 0.8894\n",
            "Epoch 10/16\n",
            "11264/31653 [=========>....................] - ETA: 1:18 - loss: 0.3923 - acc: 0.8901WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/16\n",
            "31653/31653 [==============================] - 124s 4ms/step - loss: 0.4978 - acc: 0.8612\n",
            "Epoch 2/16\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.4156 - acc: 0.8789\n",
            "Epoch 3/16\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.4048 - acc: 0.8834\n",
            "Epoch 4/16\n",
            "31653/31653 [==============================] - 120s 4ms/step - loss: 0.4032 - acc: 0.8848\n",
            "Epoch 5/16\n",
            "31653/31653 [==============================] - 120s 4ms/step - loss: 0.4009 - acc: 0.8853\n",
            "Epoch 6/16\n",
            "31653/31653 [==============================] - 124s 4ms/step - loss: 0.4006 - acc: 0.8865\n",
            "Epoch 7/16\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.3965 - acc: 0.8874\n",
            "Epoch 8/16\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.3972 - acc: 0.8879\n",
            "Epoch 9/16\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.3981 - acc: 0.8894\n",
            "Epoch 10/16\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.3957 - acc: 0.8894\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.3957 - acc: 0.8894\n",
            "Epoch 11/16\n",
            "Epoch 11/16\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.3979 - acc: 0.8894\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.3979 - acc: 0.8894\n",
            "Epoch 12/16\n",
            "Epoch 12/16\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.4020 - acc: 0.8896\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.4020 - acc: 0.8896\n",
            "Epoch 13/16\n",
            "Epoch 13/16\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.3975 - acc: 0.8900\n",
            "31653/31653 [==============================] - 121s 4ms/step - loss: 0.3975 - acc: 0.8900\n",
            "Epoch 14/16\n",
            "Epoch 14/16\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.4057 - acc: 0.8897\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.4057 - acc: 0.8897\n",
            "Epoch 15/16\n",
            "Epoch 15/16\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.3977 - acc: 0.8897\n",
            "31653/31653 [==============================] - 122s 4ms/step - loss: 0.3977 - acc: 0.8897\n",
            "Epoch 16/16\n",
            "Epoch 16/16\n",
            "31653/31653 [==============================] - 120s 4ms/step - loss: 0.4000 - acc: 0.8900\n",
            "31653/31653 [==============================] - 120s 4ms/step - loss: 0.4000 - acc: 0.8900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yfkfElIialcz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rmb-dVhiUVV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tR9caCGEhEKS",
        "colab_type": "code",
        "outputId": "e739afa9-a9db-4e2b-c3c5-5a0214bca2f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1016
        }
      },
      "cell_type": "code",
      "source": [
        "# from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
        "# from keras.layers import Dropout\n",
        "# from keras.layers import Dense\n",
        "# from keras import optimizers,callbacks\n",
        "# import keras\n",
        "# model2 = Sequential()\n",
        "# model2.add(Embedding(1000, 1000 ,input_length=25))\n",
        "\n",
        "\n",
        "\n",
        "# model2.add(Conv1D(256, 5, activation=r'elu'))\n",
        "# model2.add(Dropout(0.6))\n",
        "# model2.add(Conv1D(512, 5, activation='elu'))\n",
        "# model2.add(Dropout(0.3))\n",
        "# model2.add(Conv1D(1024, 5, activation='elu'))\n",
        "# model2.add(Dropout(0.5))\n",
        "\n",
        "# model2.add(Flatten())\n",
        "\n",
        "# model2.add(Dense(400, activation='elu'))\n",
        "# model2.add(Dense(100, activation='elu'))\n",
        "# model2.add(Dense(8, activation='softmax'))\n",
        "\n",
        "# #adam = optimizers.adam(lr = 0.0005)\n",
        "# adam = optimizers.adam(lr = 0.0026)\n",
        "# reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
        "# model2.compile(optimizer=adam,\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['acc'])\n",
        "# history = model2.fit(x_train, labelDataBinary,\n",
        "#                     epochs=16,\n",
        "#                     validation_split=0,\n",
        "#                     class_weight = class_weights,\n",
        "#                    callbacks=[reduce_lr])\n",
        "\n",
        "# model2.save('/content/m2.h5')\n",
        "# #0.85621\n",
        "# predic2 = pd.Series(predict(model2, x_test))\n",
        "# submission = pd.concat([test.ID.astype(np.int), predic2], axis = 1)\n",
        "# submission.columns = ['ID' , 'MaterialType']\n",
        "# submission.to_csv('/content/submition_model2_add.csv', index = False, header = True)  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "31653/31653 [==============================] - 36s 1ms/step - loss: 5.2104 - acc: 0.6757\n",
            "Epoch 2/16\n",
            "  160/31653 [..............................] - ETA: 36s - loss: 4.5332 - acc: 0.7188"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31653/31653 [==============================] - 34s 1ms/step - loss: 5.0697 - acc: 0.6855\n",
            "Epoch 3/16\n",
            "31653/31653 [==============================] - 34s 1ms/step - loss: 5.0712 - acc: 0.6854\n",
            "Epoch 4/16\n",
            "27040/31653 [========================>.....] - ETA: 4s - loss: 5.0816 - acc: 0.6847"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9cd342842424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                    callbacks=[reduce_lr])\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/m2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "K-vJg1_cvU9W",
        "colab_type": "code",
        "outputId": "7c409dac-9bfd-4980-ed0f-bd4c6a6c2e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers,callbacks\n",
        "import keras\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(1000, 1000 ,input_length=25))\n",
        "\n",
        "\n",
        "model3.add(CuDNNGRU(600, return_sequences = True))\n",
        "model3.add(Dropout(0.7))\n",
        "\n",
        "model3.add(CuDNNGRU(600, return_sequences = True))\n",
        "model3.add(Dropout(0.5))\n",
        "\n",
        "model3.add(CuDNNGRU(800))\n",
        "model3.add(Dropout(0.4))\n",
        "\n",
        "model3.add(Dense(200, activation='elu'))\n",
        "model3.add(Dense(50, activation='elu'))\n",
        "model3.add(Dense(8, activation='softmax'))\n",
        "\n",
        "adam = optimizers.adam(lr = 0.0014)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
        "model3.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model3.fit(x_train, labelDataBinary,\n",
        "                    epochs=16,\n",
        "                    validation_split=0,\n",
        "                    class_weight = class_weights,\n",
        "                   callbacks=[reduce_lr])\n",
        "\n",
        "model3.save('/content/m3.h5')\n",
        "#0.87688 \n",
        "predic3 = pd.Series(predict(model3, x_test))\n",
        "submission = pd.concat([test.ID.astype(np.int), predic3], axis = 1)\n",
        "submission.columns = ['ID' , 'MaterialType']\n",
        "submission.to_csv('/content/submition_model3_add_2.csv', index = False, header = True)  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "31653/31653 [==============================] - 70s 2ms/step - loss: 0.5129 - acc: 0.8600\n",
            "Epoch 2/16\n",
            "   64/31653 [..............................] - ETA: 1:06 - loss: 0.5209 - acc: 0.8594"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.4108 - acc: 0.8769\n",
            "Epoch 3/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3832 - acc: 0.8814\n",
            "Epoch 4/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3691 - acc: 0.8840\n",
            "Epoch 5/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3593 - acc: 0.8868\n",
            "Epoch 6/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3560 - acc: 0.8878\n",
            "Epoch 7/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3552 - acc: 0.8874\n",
            "Epoch 8/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3447 - acc: 0.8894\n",
            "Epoch 9/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3413 - acc: 0.8903\n",
            "Epoch 10/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3411 - acc: 0.8912\n",
            "Epoch 11/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3486 - acc: 0.8883\n",
            "Epoch 12/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3584 - acc: 0.8868\n",
            "Epoch 13/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3520 - acc: 0.8872\n",
            "Epoch 14/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3542 - acc: 0.8875\n",
            "Epoch 15/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3594 - acc: 0.8864\n",
            "Epoch 16/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3583 - acc: 0.8867\n",
            "Epoch 1/16\n",
            "31653/31653 [==============================] - 70s 2ms/step - loss: 0.5129 - acc: 0.8600\n",
            "Epoch 2/16\n",
            "   64/31653 [..............................] - ETA: 1:06 - loss: 0.5209 - acc: 0.8594"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.4108 - acc: 0.8769\n",
            "Epoch 3/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3832 - acc: 0.8814\n",
            "Epoch 4/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3691 - acc: 0.8840\n",
            "Epoch 5/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3593 - acc: 0.8868\n",
            "Epoch 6/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3560 - acc: 0.8878\n",
            "Epoch 7/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3552 - acc: 0.8874\n",
            "Epoch 8/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3447 - acc: 0.8894\n",
            "Epoch 9/16\n",
            "31653/31653 [==============================] - 68s 2ms/step - loss: 0.3413 - acc: 0.8903\n",
            "Epoch 10/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3411 - acc: 0.8912\n",
            "Epoch 11/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3486 - acc: 0.8883\n",
            "Epoch 12/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3584 - acc: 0.8868\n",
            "Epoch 13/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3520 - acc: 0.8872\n",
            "Epoch 14/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3542 - acc: 0.8875\n",
            "Epoch 15/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3594 - acc: 0.8864\n",
            "Epoch 16/16\n",
            "31653/31653 [==============================] - 67s 2ms/step - loss: 0.3583 - acc: 0.8867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4CUA9qwchNgt",
        "colab_type": "code",
        "outputId": "a2853bb5-e111-418a-ac61-4a105dfef65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers,callbacks\n",
        "import keras\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(1000, 1000 ,input_length=25))\n",
        "\n",
        "\n",
        "model4.add(CuDNNGRU(600, return_sequences = True))\n",
        "model4.add(Dropout(0.7))\n",
        "\n",
        "model4.add(CuDNNGRU(600))\n",
        "model4.add(Dropout(0.6))\n",
        "\n",
        "model4.add(Dense(100, activation='elu'))\n",
        "model4.add(Dense(50, activation='relu'))\n",
        "model4.add(Dense(8, activation='softmax'))\n",
        "\n",
        "adam = optimizers.adam(lr = 0.001)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
        "model4.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model4.fit(x_train, labelDataBinary,\n",
        "                    epochs=16,\n",
        "                    validation_split=0,\n",
        "                    class_weight = class_weights,\n",
        "                   callbacks=[reduce_lr])\n",
        "\n",
        "model4.save('/content/m4.h5')\n",
        "#0.87181 \n",
        "predic4 = pd.Series(predict(model4, x_test))\n",
        "submission = pd.concat([test.ID.astype(np.int), predic4], axis = 1)\n",
        "submission.columns = ['ID' , 'MaterialType']\n",
        "submission.to_csv('/content/submition_model4_add.1.csv', index = False, header = True)  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "31653/31653 [==============================] - 44s 1ms/step - loss: 0.4981 - acc: 0.8616\n",
            "Epoch 2/16\n",
            "   96/31653 [..............................] - ETA: 43s - loss: 0.4070 - acc: 0.8958"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.3960 - acc: 0.8815\n",
            "Epoch 3/16\n",
            "31653/31653 [==============================] - 43s 1ms/step - loss: 0.3708 - acc: 0.8853\n",
            "Epoch 4/16\n",
            "31653/31653 [==============================] - 43s 1ms/step - loss: 0.3513 - acc: 0.8911\n",
            "Epoch 5/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.3364 - acc: 0.8939\n",
            "Epoch 6/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.3260 - acc: 0.8953\n",
            "Epoch 7/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.3155 - acc: 0.8984\n",
            "Epoch 8/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.3064 - acc: 0.9003\n",
            "Epoch 9/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.2979 - acc: 0.9029\n",
            "Epoch 10/16\n",
            "31653/31653 [==============================] - 43s 1ms/step - loss: 0.2934 - acc: 0.9038\n",
            "Epoch 11/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.2882 - acc: 0.9049\n",
            "Epoch 12/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.2819 - acc: 0.9058\n",
            "Epoch 13/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.2802 - acc: 0.9064\n",
            "Epoch 14/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.2757 - acc: 0.9088\n",
            "Epoch 15/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.2705 - acc: 0.9084\n",
            "Epoch 16/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.2691 - acc: 0.9094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7OmSE-mdtAW-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8EGozWZ3UdC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Using Embedding Layer**"
      ]
    },
    {
      "metadata": {
        "id": "CNdQiMIGwjQD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"from keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "\n",
        "model5 = Sequential()\n",
        "model5.add(Embedding(1000, 300, input_length=25, weights=[embedding_matrix], trainable=False))\n",
        "\n",
        "model5.add(Conv1D(64, 5, activation='relu'))\n",
        "model5.add(MaxPooling1D(pool_size=4))\n",
        "\n",
        "\n",
        "model5.add(LSTM(1000, recurrent_dropout = 0.3))\n",
        "model5.add(Dropout(0.35))\n",
        "model5.add(Dense(8, activation='softmax'))\n",
        "\n",
        "model5.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model5.fit(x_train, labelDataBinary,\n",
        "                    epochs=16,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2,\n",
        "                    class_weight = class_weights)\n",
        "\n",
        "\n",
        "model5.save('/content/m5.h5')\n",
        "predic5 = pd.Series(predict(model5, x_test))\n",
        "submission = pd.concat([test.ID.astype(np.int), predic5], axis = 1)\n",
        "submission.columns = ['ID' , 'MaterialType']\n",
        "submission.to_csv('/content/submition_model5.csv', index = False, header = True)  \n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vrryo7yGt_Mc",
        "colab_type": "code",
        "outputId": "49172c3e-99be-46ba-b79b-8c19bf61e751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1193
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers,callbacks\n",
        "import keras\n",
        "model6 = Sequential()\n",
        "model6.add(Embedding(1000, 1000 ,input_length=25))\n",
        "\n",
        "\n",
        "model6.add(CuDNNGRU(600, return_sequences = True))\n",
        "#model.add(Dropout(0.6))\n",
        "model6.add(Dropout(0.7))\n",
        "\n",
        "model6.add(CuDNNGRU(500))\n",
        "model6.add(Dropout(0.7))\n",
        "\n",
        "model6.add(Dense(100, activation='relu'))\n",
        "model6.add(Dense(50, activation='elu'))\n",
        "model6.add(Dense(8, activation='softmax'))\n",
        "\n",
        "adam = optimizers.adam(lr = 0.001)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
        "model6.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model6.fit(x_train, labelDataBinary,\n",
        "                    epochs=16,\n",
        "                    validation_split=0,\n",
        "                    class_weight = class_weights,\n",
        "                   callbacks=[reduce_lr])\n",
        "\n",
        "#model6.save('/content/model_morefeatures.h5')\n",
        "#v1_0.87181 \n",
        "#0.87181 \n",
        "#0.87695\n",
        "predic6 = pd.Series(predict(model6, x_test))\n",
        "submission = pd.concat([test.ID.astype(np.int), predic6], axis = 1)\n",
        "submission.columns = ['ID' , 'MaterialType']\n",
        "submission.to_csv('/content/submition_model6_add.1.csv', index = False, header = True)  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.4913 - acc: 0.8606\n",
            "Epoch 2/16\n",
            "   96/31653 [..............................] - ETA: 39s - loss: 0.4601 - acc: 0.8750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3912 - acc: 0.8815\n",
            "Epoch 3/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3625 - acc: 0.8866\n",
            "Epoch 4/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3479 - acc: 0.8907\n",
            "Epoch 5/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3342 - acc: 0.8929\n",
            "Epoch 6/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3219 - acc: 0.8961\n",
            "Epoch 7/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3149 - acc: 0.8972\n",
            "Epoch 8/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3063 - acc: 0.9012\n",
            "Epoch 9/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.3031 - acc: 0.9009\n",
            "Epoch 10/16\n",
            "22272/31653 [====================>.........] - ETA: 14s - loss: 0.2895 - acc: 0.9033Epoch 1/16\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.4913 - acc: 0.8606\n",
            "Epoch 2/16\n",
            "   96/31653 [..............................] - ETA: 39s - loss: 0.4601 - acc: 0.8750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3912 - acc: 0.8815\n",
            "Epoch 3/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3625 - acc: 0.8866\n",
            "Epoch 4/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3479 - acc: 0.8907\n",
            "Epoch 5/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3342 - acc: 0.8929\n",
            "Epoch 6/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3219 - acc: 0.8961\n",
            "Epoch 7/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3149 - acc: 0.8972\n",
            "Epoch 8/16\n",
            "31653/31653 [==============================] - 40s 1ms/step - loss: 0.3063 - acc: 0.9012\n",
            "Epoch 9/16\n",
            "31653/31653 [==============================] - 42s 1ms/step - loss: 0.3031 - acc: 0.9009\n",
            "Epoch 10/16\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.2945 - acc: 0.9032\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.2945 - acc: 0.9032\n",
            "Epoch 11/16Epoch 11/16\n",
            "   32/31653 [..............................] - ETA: 43s - loss: 0.2521 - acc: 0.9062\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2863 - acc: 0.9053\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2863 - acc: 0.9053\n",
            "Epoch 12/16\n",
            "   32/31653 [..............................] - ETA: 46s - loss: 0.2921 - acc: 0.8438Epoch 12/16\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2868 - acc: 0.9051\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2868 - acc: 0.9051\n",
            "Epoch 13/16\n",
            "   32/31653 [..............................] - ETA: 43s - loss: 0.3009 - acc: 0.8750Epoch 13/16\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2836 - acc: 0.9072\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2836 - acc: 0.9072\n",
            "Epoch 14/16\n",
            "   32/31653 [..............................] - ETA: 42s - loss: 0.3222 - acc: 0.9375Epoch 14/16\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2802 - acc: 0.9071\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2802 - acc: 0.9071\n",
            "Epoch 15/16\n",
            "Epoch 15/16\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2768 - acc: 0.9075\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2768 - acc: 0.9075\n",
            "Epoch 16/16\n",
            "Epoch 16/16\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2768 - acc: 0.9082\n",
            "31653/31653 [==============================] - 41s 1ms/step - loss: 0.2768 - acc: 0.9082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V030IwV313mU",
        "colab_type": "code",
        "outputId": "c6e9ee63-a9f6-4a62-db75-87befeb3e71e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers,callbacks\n",
        "import keras\n",
        "model6 = Sequential()\n",
        "model6.add(Embedding(1600, 1600 ,input_length=25))\n",
        "\n",
        "\n",
        "model6.add(CuDNNGRU(600, return_sequences = True))\n",
        "#model.add(Dropout(0.6))\n",
        "model6.add(Dropout(0.7))\n",
        "\n",
        "model6.add(CuDNNGRU(500))\n",
        "model6.add(Dropout(0.6))\n",
        "\n",
        "model6.add(Dense(100, activation='elu'))\n",
        "model6.add(Dense(50, activation='elu'))\n",
        "model6.add(Dense(8, activation='softmax'))\n",
        "\n",
        "adam = optimizers.adam(lr = 0.0014)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)\n",
        "model6.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model6.fit(x_train, labelDataBinary,\n",
        "                    epochs=16,\n",
        "                    validation_split=0,\n",
        "                    class_weight = class_weights,\n",
        "                   callbacks=[reduce_lr])\n",
        "\n",
        "model6.save('/content/model_morefeatures.h5')\n",
        "#v1_0.87181 \n",
        "#0.87181 \n",
        "#0.87695\n",
        "predic6 = pd.Series(predict(model6, x_test))\n",
        "submission = pd.concat([test.ID.astype(np.int), predic6], axis = 1)\n",
        "submission.columns = ['ID' , 'MaterialType']\n",
        "submission.to_csv('/content/submition_model_add_v1.csv', index = False, header = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "Epoch 1/16\n",
            "31653/31653 [==============================] - 48s 2ms/step - loss: 0.4869 - acc: 0.8620\n",
            "31653/31653 [==============================] - 48s 2ms/step - loss: 0.4869 - acc: 0.8620\n",
            "Epoch 2/16\n",
            "   32/31653 [..............................] - ETA: 46s - loss: 0.4096 - acc: 0.8125Epoch 2/16\n",
            "   96/31653 [..............................] - ETA: 46s - loss: 0.3844 - acc: 0.8854"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.3938 - acc: 0.8806\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.3938 - acc: 0.8806\n",
            "Epoch 3/16\n",
            "   32/31653 [..............................] - ETA: 46s - loss: 0.1168 - acc: 0.9375Epoch 3/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3687 - acc: 0.8845\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3687 - acc: 0.8845\n",
            "Epoch 4/16Epoch 4/16\n",
            "   32/31653 [..............................] - ETA: 49s - loss: 0.3097 - acc: 0.9062\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3640 - acc: 0.8866\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3640 - acc: 0.8866\n",
            "Epoch 5/16\n",
            "   32/31653 [..............................] - ETA: 49s - loss: 0.3721 - acc: 0.8438Epoch 5/16\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.3506 - acc: 0.8890\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.3506 - acc: 0.8890\n",
            "Epoch 6/16\n",
            "Epoch 6/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3482 - acc: 0.8901\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3482 - acc: 0.8901\n",
            "Epoch 7/16\n",
            "Epoch 7/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3426 - acc: 0.8921\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3426 - acc: 0.8921\n",
            "Epoch 8/16\n",
            "   32/31653 [..............................] - ETA: 46s - loss: 0.2591 - acc: 0.9062Epoch 8/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3418 - acc: 0.8927\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3418 - acc: 0.8927\n",
            "Epoch 9/16\n",
            "   32/31653 [..............................] - ETA: 46s - loss: 0.3219 - acc: 0.8750Epoch 9/16\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.3384 - acc: 0.8929\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.3384 - acc: 0.8929\n",
            "Epoch 10/16\n",
            "   32/31653 [..............................] - ETA: 48s - loss: 0.3426 - acc: 0.9062Epoch 10/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3381 - acc: 0.8949\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3381 - acc: 0.8949\n",
            "Epoch 11/16\n",
            "Epoch 11/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3383 - acc: 0.8924\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3383 - acc: 0.8924\n",
            "Epoch 12/16\n",
            "   32/31653 [..............................] - ETA: 48s - loss: 0.2834 - acc: 0.8750Epoch 12/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3390 - acc: 0.8925\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3390 - acc: 0.8925\n",
            "Epoch 13/16\n",
            "Epoch 13/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3380 - acc: 0.8921\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3380 - acc: 0.8921\n",
            "Epoch 14/16\n",
            "   32/31653 [..............................] - ETA: 50s - loss: 0.5874 - acc: 0.7500Epoch 14/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3418 - acc: 0.8924\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3418 - acc: 0.8924\n",
            "Epoch 15/16\n",
            "   32/31653 [..............................] - ETA: 50s - loss: 0.1738 - acc: 0.9688Epoch 15/16\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3381 - acc: 0.8923\n",
            "31653/31653 [==============================] - 46s 1ms/step - loss: 0.3381 - acc: 0.8923\n",
            "Epoch 16/16\n",
            "Epoch 16/16\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.3442 - acc: 0.8893\n",
            "31653/31653 [==============================] - 47s 1ms/step - loss: 0.3442 - acc: 0.8893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pDbtHE-qgu7u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission.to_csv('/content/submition_model_impr.csv', index = False, header = True)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZReVSR3gy5kI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "reverseLabelDict = {}\n",
        "\n",
        "for key, value in labelDict.items():\n",
        "  reverseLabelDict[value] = key\n",
        "  \n",
        "predictions = model.predict(x_test)\n",
        "predictions = pd.Series([np.argmax(i) for i in predictions], index = test.index)\n",
        "predictions = predictions.map(reverseLabelDict)\n",
        "\n",
        "submission = pd.concat([test.ID.astype(np.int), predictions], axis = 1)\n",
        "submission.columns = ['ID' , 'MaterialType']\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJCiVVuTQ-x6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " # submission.to_csv('/content/submition_3.1_05_100_50_8.csv', index = False, header = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w4azj14Q4A2R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\"reverseLabelDict = {}\n",
        "\n",
        "for key, value in labelDict.items():\n",
        "  reverseLabelDict[value] = key\n",
        "def predict(model, x_test):\n",
        "  predictions = model.predict(x_test)\n",
        "  predictions = pd.Series([np.argmax(i) for i in predictions], index = test.index)\n",
        "  predictions = predictions.map(reverseLabelDict)\n",
        "  submission = pd.concat([test.ID.astype(np.int), predictions], axis = 1)\n",
        "  submission.columns = ['ID' , 'MaterialType']\n",
        "  return predictions\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ie1SXk352-SI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_model = 6\n",
        "predic1 = pd.Series(predict(model1, x_test))\n",
        "predic2 = pd.Series(predict(model2, x_test))\n",
        "predic3 = pd.Series(predict(model3, x_test))\n",
        "predic4 = pd.Series(predict(model4, x_test))\n",
        "predic5 = pd.Series(predict(model5, x_test))\n",
        "predic6 = pd.Series(predict(model6, x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RjMF0-A7FJZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"total = pd.DataFrame(pd.concat([predic1, predic2, predic3, predic4, predic5,predic6], axis = 1))\n",
        "submissions = total.mode(axis = 1)[0]\n",
        "submission = pd.concat([test.ID.astype(np.int), predictions], axis = 1)\n",
        "submission.columns = ['ID' , 'MaterialType']\n",
        "submission.to_csv('sub-agg.csv', index = False, header = True)\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LrPJl9KF8O40",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total = pd.DataFrame(pd.concat([predic1, predic2, predic3, predic4, predic5,predic6], axis = 1))\n",
        "submissions = total.mode(axis = 1)[0]\n",
        "#submissions = pd.concat([test.ID.astype(np.int), predictions], axis = 1)\n",
        "submissions.columns = ['ID' , 'MaterialType']\n",
        "submissions.to_csv('/content/sub-final.csv', index = False, header = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-9IE2z4V912",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}