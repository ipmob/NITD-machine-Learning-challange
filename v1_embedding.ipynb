{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/amanjain1397/zip-the-code-1.0/blob/master/v_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "7Pwq9fDJu2sG",
    "outputId": "efb82fad-dcd0-433b-aabd-e71563fe3419"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CmLSEOyhu7oS",
    "outputId": "ed53083e-afb0-4b39-d90e-844446f81651"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tTl_vxGPvplJ",
    "outputId": "67df0847-e338-41db-8d4f-24b14f8d2f4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "sVa2BcBlvqCU",
    "outputId": "38fb0d54-351e-411a-bb4b-6faf29de34eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipmob/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ipmob/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import keras\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvx0EdUFvsqf"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    #Lowering case the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Removing numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    #Removing punctuations\n",
    "    import string\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    #Removing stop words\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([ i for i in tokens if not i in stopwords])\n",
    "    \n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Eoq0CcnvMV_G",
    "outputId": "ffc8f45c-4a52-4321-cfb0-73dae0f94b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36088 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/train_file.csv')\n",
    "test = pd.read_csv('data/test_file.csv')\n",
    "sample = pd.read_csv('data/results_file.csv')\n",
    "\n",
    "data.loc[data.Subjects.isnull(), 'Subjects'] = ''\n",
    "test.loc[test.Subjects.isnull(), 'Subjects'] = ''\n",
    "\n",
    "data['combined'] = data.Subjects.str.cat(' ' + data.Title)\n",
    "test['combined'] = test.Subjects.str.cat(' ' + test.Title)\n",
    "\n",
    "dataMatType = data.MaterialType\n",
    "data.drop(labels = ['MaterialType'], axis = 1, inplace = True)\n",
    "\n",
    "data.combined = data.combined.apply(preprocess_text)\n",
    "test.combined = test.combined.apply(preprocess_text)\n",
    "'''\n",
    "data.Subjects = data.Subjects.apply(preprocess_text)\n",
    "data.Title = data.Title.apply(preprocess_text)\n",
    "test.Subjects = test.Subjects.apply(preprocess_text)\n",
    "test.Title = test.Title.apply(preprocess_text)\n",
    "'''\n",
    "flag = -1\n",
    "labelDict = {}\n",
    "\n",
    "for key in dataMatType.value_counts().keys():\n",
    "  flag += 1\n",
    "  labelDict[key] = flag\n",
    "  \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 10                             \n",
    "\n",
    "max_words = 1000                                    \n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data.combined)\n",
    "\n",
    "dataSequences = tokenizer.texts_to_sequences(data.combined)\n",
    "testSequences = tokenizer.texts_to_sequences(test.combined)\n",
    "\n",
    "data_word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(data_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmgGkE7lvwc0"
   },
   "outputs": [],
   "source": [
    "from keras import preprocessing\n",
    "x_train = preprocessing.sequence.pad_sequences(dataSequences, maxlen = 10)\n",
    "x_test = preprocessing.sequence.pad_sequences(testSequences, maxlen = 10)\n",
    "\n",
    "train_label = dataMatType.map(labelDict)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "labelDataBinary = to_categorical(train_label)\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(dataMatType), dataMatType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PFlbzeBoGMX9",
    "outputId": "4939380c-9475-4ef0-ce05-17503f4d005d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('../glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_dim = 300\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in data_word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "p8lV4j7qvUNd",
    "outputId": "a1af66d0-3193-4146-db31-ba67cc269cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25322 samples, validate on 6331 samples\n",
      "Epoch 1/8\n",
      "25322/25322 [==============================] - 69s 3ms/step - loss: 0.5867 - acc: 0.8380 - val_loss: 0.4669 - val_acc: 0.8728\n",
      "Epoch 2/8\n",
      "25322/25322 [==============================] - 52s 2ms/step - loss: 0.4618 - acc: 0.8700 - val_loss: 0.4384 - val_acc: 0.8755\n",
      "Epoch 3/8\n",
      "25322/25322 [==============================] - 53s 2ms/step - loss: 0.4402 - acc: 0.8750 - val_loss: 0.4419 - val_acc: 0.8825\n",
      "Epoch 4/8\n",
      "25322/25322 [==============================] - 54s 2ms/step - loss: 0.4262 - acc: 0.8784 - val_loss: 0.4355 - val_acc: 0.8825\n",
      "Epoch 5/8\n",
      "25322/25322 [==============================] - 53s 2ms/step - loss: 0.4172 - acc: 0.8786 - val_loss: 0.4262 - val_acc: 0.8814\n",
      "Epoch 6/8\n",
      "25322/25322 [==============================] - 54s 2ms/step - loss: 0.4124 - acc: 0.8816 - val_loss: 0.4395 - val_acc: 0.8820\n",
      "Epoch 7/8\n",
      "25322/25322 [==============================] - 55s 2ms/step - loss: 0.4045 - acc: 0.8826 - val_loss: 0.4416 - val_acc: 0.8823\n",
      "Epoch 8/8\n",
      "25322/25322 [==============================] - 56s 2ms/step - loss: 0.4042 - acc: 0.8844 - val_loss: 0.4369 - val_acc: 0.8793\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 300, input_length=10))\n",
    "\n",
    "'''model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "'''\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 3,  activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(400, recurrent_dropout = 0.6, return_sequences = True))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(LSTM(400, recurrent_dropout = 0.2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, labelDataBinary,\n",
    "                    epochs=8,\n",
    "                    validation_split=0.2,\n",
    "                    class_weight = class_weights)\n",
    "\n",
    "model.save('m1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-vJg1_cvU9W"
   },
   "outputs": [],
   "source": [
    "#model.save('./models/m1.h5')\n",
    "model.save('m1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8EGozWZ3UdC"
   },
   "source": [
    "**Using Embedding Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNdQiMIGwjQD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25322 samples, validate on 6331 samples\n",
      "Epoch 1/8\n",
      "25322/25322 [==============================] - 45s 2ms/step - loss: 0.5646 - acc: 0.8440 - val_loss: 0.4672 - val_acc: 0.8574\n",
      "Epoch 2/8\n",
      "25322/25322 [==============================] - 42s 2ms/step - loss: 0.4551 - acc: 0.8647 - val_loss: 0.4274 - val_acc: 0.8686\n",
      "Epoch 3/8\n",
      "25322/25322 [==============================] - 41s 2ms/step - loss: 0.4218 - acc: 0.8710 - val_loss: 0.4192 - val_acc: 0.8711\n",
      "Epoch 4/8\n",
      "25322/25322 [==============================] - 40s 2ms/step - loss: 0.3957 - acc: 0.8754 - val_loss: 0.4168 - val_acc: 0.8724\n",
      "Epoch 5/8\n",
      "25322/25322 [==============================] - 45s 2ms/step - loss: 0.3713 - acc: 0.8809 - val_loss: 0.4109 - val_acc: 0.8768\n",
      "Epoch 6/8\n",
      "25322/25322 [==============================] - 45s 2ms/step - loss: 0.3469 - acc: 0.8870 - val_loss: 0.4196 - val_acc: 0.8751\n",
      "Epoch 7/8\n",
      "25322/25322 [==============================] - 49s 2ms/step - loss: 0.3189 - acc: 0.8929 - val_loss: 0.4198 - val_acc: 0.8757\n",
      "Epoch 8/8\n",
      "25322/25322 [==============================] - 46s 2ms/step - loss: 0.2891 - acc: 0.9017 - val_loss: 0.4393 - val_acc: 0.8774\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 300, input_length=10, weights=[embedding_matrix], trainable=False))\n",
    "\n",
    "'''model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "'''\n",
    "\n",
    "model.add(LSTM(1000, recurrent_dropout = 0.3))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, labelDataBinary,\n",
    "                    epochs=8,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZReVSR3gy5kI"
   },
   "outputs": [],
   "source": [
    "reverseLabelDict = {}\n",
    "\n",
    "for key, value in labelDict.items():\n",
    "  reverseLabelDict[value] = key\n",
    "  \n",
    "predictions = model.predict(x_test)\n",
    "predictions = pd.Series([np.argmax(i) for i in predictions], index = test.index)\n",
    "predictions = predictions.map(reverseLabelDict)\n",
    "\n",
    "submission = pd.concat([test.ID.astype(np.int), predictions], axis = 1)\n",
    "submission.columns = ['ID' , 'MaterialType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJCiVVuTQ-x6"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('sub-dl.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4azj14Q4A2R"
   },
   "outputs": [],
   "source": [
    "def predict(model, x_test):\n",
    "  predictions = model.predict(x_test)\n",
    "  predictions = pd.Series([np.argmax(i) for i in predictions], index = test.index)\n",
    "  predictions = predictions.map(reverseLabelDict)\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ie1SXk352-SI"
   },
   "outputs": [],
   "source": [
    "#num_model = 5\n",
    "predic1 = pd.Series(predict(model1, x_test))\n",
    "#predic2 = pd.Series(predict(model2, x_test))\n",
    "#predic3 = pd.Series(predict(model3, x_test))\n",
    "#predic4 = pd.Series(predict(model4, x_test))\n",
    "#predic5 = pd.Series(predict(model5, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RjMF0-A7FJZ"
   },
   "outputs": [],
   "source": [
    "#total = pd.DataFrame(pd.concat([predic1, predic2, predic3, predic4, predic5], axis = 1))\n",
    "total = pd.DataFrame(pd.concat([predic1], axis = 1))\n",
    "submissions = total.mode(axis = 1)[0]\n",
    "submission = pd.concat([test.ID.astype(np.int), predictions], axis = 1)\n",
    "submission.columns = ['ID' , 'MaterialType']\n",
    "submission.to_csv('sub-mew.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1094
    },
    "colab_type": "code",
    "id": "LrPJl9KF8O40",
    "outputId": "97116bc7-9e22-49c5-e434-bd56c460d593"
   },
   "outputs": [],
   "source": [
    "submissions = total.mode(axis = 1)[0]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Copy of v01 LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
